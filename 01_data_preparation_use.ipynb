{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/Training_set_values.csv', index_col='id')\n",
    "X_test = pd.read_csv('data/Test_set_values.csv', index_col='id')\n",
    "y_train = pd.read_csv('data/Training_set_labels.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the X and y train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train.merge(y_train, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merged the X train and y train data to build a dataframe that we could use to testing our different models on. The data set from where the data came did not have a y test dataset. We will split the merged dataset and create a hold out group later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recorded_by'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funder: 1898 unique values; source of funding less relevant to pump functionality which should be better captured by installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.funder.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['funder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['extraction_type'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['extraction_type_group'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['extraction_type_class'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['subvillage'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['region'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['region_code'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['district_code'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['lga'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['ward'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount_tsh - Total static head (amount water available to waterpoint)      **DROP** A majority of the rows for this feature do not have values. \n",
    "\n",
    "# date_recorded - The date the row was entered                               **DROP**\n",
    "\n",
    "# funder - Who funded the well                                               **DROP**\n",
    "\n",
    "# gps_height - Altitude of the well\n",
    "\n",
    "# installer - Organization that installed the well                           **DROP**\n",
    "\n",
    "# wpt_name - Name of the waterpoint if there is one                          **DROP**\n",
    "\n",
    "# num_private -                                                              **DROP**\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ***LOCATION METRICS***\n",
    "\n",
    "# longitude - GPS coordinate\n",
    "# latitude - GPS coordinate\n",
    "# basin - Geographic water basin\n",
    "# subvillage - Geographic location                                           **DROP**\n",
    "# region - Geographic location\n",
    "# region_code - Geographic location (coded)                                  **DROP** 'region' has more information\n",
    "# district_code - Geographic location (coded)\n",
    "# lga - Geographic location                                                  **DROP**\n",
    "# ward - Geographic location                                                 **DROP**\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# population - Population around the well\n",
    "\n",
    "# public_meeting - True/False\n",
    "\n",
    "# recorded_by - Group entering this row of data                              **DROP**\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# scheme_management - Who operates the waterpoint\n",
    "# scheme_name - Who operates the waterpoint                                  **DROP**\n",
    "\n",
    "# permit - If the waterpoint is permitted\n",
    "\n",
    "# construction_year - Year the waterpoint was constructed\n",
    "\n",
    "# extraction_type - The kind of extraction the waterpoint uses\n",
    "# extraction_type_group - The kind of extraction the waterpoint uses         **DROP**\n",
    "# extraction_type_class - The kind of extraction the waterpoint uses         **DROP**\n",
    "\n",
    "# management - How the waterpoint is managed\n",
    "# management_group - How the waterpoint is managed                           **DROP**\n",
    "\n",
    "# payment - What the water costs\n",
    "# payment_type - What the water costs                                        **DROP**\n",
    "\n",
    "# water_quality - The quality of the water\n",
    "# quality_group - The quality of the water                                   **DROP**\n",
    "\n",
    "# quantity - The quantity of water\n",
    "# quantity_group - The quantity of water                                     **DROP**                              \n",
    "\n",
    "# source - The source of the water\n",
    "# source_type - The source of the water                                      **DROP**\n",
    "# source_class - The source of the water                                     **DROP**\n",
    "\n",
    "# waterpoint_type - The kind of waterpoint\n",
    "# waterpoint_type_group - The kind of waterpoint                             **DROP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funder - Who funded the well\n",
    "# gps_height - Altitude of the well\n",
    "# installer - Organization that installed the well\n",
    "# longitude - GPS coordinate\n",
    "# latitude - GPS coordinate\n",
    "# basin - Geographic water basin\n",
    "# region - Geographic location\n",
    "# district_code - Geographic location (coded)\n",
    "# population - Population around the well\n",
    "# public_meeting - True/False\n",
    "# scheme_management - Who operates the waterpoint\n",
    "# permit - If the waterpoint is permitted\n",
    "# construction_year - Year the waterpoint was constructed\n",
    "# extraction_type - The kind of extraction the waterpoint uses\n",
    "# management - How the waterpoint is managed\n",
    "# payment - What the water costs\n",
    "# water_quality - The quality of the water\n",
    "# quantity - The quantity of water\n",
    "# source - The source of the water\n",
    "# waterpoint_type - The kind of waterpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['funder'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['gps_height'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['installer'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['basin'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['region'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['district_code'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['population'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['public_meeting'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['scheme_management'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['permit'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['construction_year'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['extraction_type'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['management'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['payment'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['water_quality'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['quantity'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['source'].value_counts())\n",
    "print('----------------------------------------------')\n",
    "print(df['waterpoint_type'].value_counts())\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_tsh'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE ENGINEERING IDEAS\n",
    "\n",
    "# water_quality by region\n",
    "# water_quality by extraction type\n",
    "# water_quality by waterpoint_type\n",
    "# water_quality by source\n",
    "# water_quality by scheme_managementa\n",
    "# water_quality by permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_quality'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['installer'].replace(to_replace='0', value='missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.installer.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['extraction_type'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['extraction_type_group'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['extraction_type_class'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['waterpoint_type'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['waterpoint_type_group'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['quantity'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['quantity_group'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['payment'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['payment_type'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['source'].value_counts()) # The kind of extraction the waterpoint uses **KEEP**\n",
    "print('----------------------------------------------')\n",
    "print(df['source_type'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')\n",
    "print(df['source_class'].value_counts()) # The kind of extraction the waterpoint uses **DROP**\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                                0\n",
       "date_recorded                             0\n",
       "funder                                 3255\n",
       "gps_height                                0\n",
       "installer                              3272\n",
       "longitude                                 0\n",
       "latitude                                  0\n",
       "wpt_name                                  0\n",
       "num_private                               0\n",
       "basin                                     0\n",
       "subvillage                              331\n",
       "region                                    0\n",
       "region_code                               0\n",
       "district_code                             0\n",
       "lga                                       0\n",
       "ward                                      0\n",
       "population                                0\n",
       "public_meeting                         2995\n",
       "recorded_by                               0\n",
       "scheme_name                           25349\n",
       "permit                                 2747\n",
       "construction_year                         0\n",
       "extraction_type_group                     0\n",
       "management                                0\n",
       "payment                                   0\n",
       "water_quality                             0\n",
       "quantity                                  0\n",
       "source                                    0\n",
       "waterpoint_type                           0\n",
       "status_group                              0\n",
       "water_quality_by_region                   0\n",
       "water_quality_by_extraction_type          0\n",
       "water_quality_by_waterpoint_type          0\n",
       "water_quality_by_source                   0\n",
       "water_quality_by_scheme_management     3506\n",
       "water_quality_by_permit                2747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['amount_tsh','date_recorded','funder','installer','wpt_name','num_private',\n",
    "                'subvillage', 'region_code', 'lga', 'ward', 'recorded_by', 'scheme_name', 'extraction_type_group', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'source_class', 'waterpoint_type_group'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['scheme_name', 'date_recorded', 'wpt_name', 'subvillage', 'lga', 'ward', 'recorded_by', \n",
    "#               'quantity_group', 'payment_type', 'funder'], axis = 1)\n",
    "# df = df.fillna('missing', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With so many unique values for some features, onehotencoding creates more than 60,000 columns (out of a dataframe with 59,400 entries), making our models computationally prohibitive.  We use common sense and topical knowledge to eliminate some features and drop those columns from our dataframe.  Here are the dropped columns and our reasoning for excluding them: <br><br>\n",
    "`date recorded`:  the age of the well is captured by the `construction_year` column <br>\n",
    "`scheme_name`:  over 28,000 missing values <br>\n",
    "`wpt_name`:  37,400 unique values <br>\n",
    "`subvillage`: 19,288 unique values and location is captured elsewhere by `latitude` and `longitude` <br>\n",
    "`lga`:  125 unique values and location is captured elsewhere by `latitude` and `longitude` <br>\n",
    "`ward`:  2092 unique values and location is captured elsewhere by `latitude` and `longitude` <br>\n",
    "`recorded_by`:  all values are the same <br>\n",
    "`quantity_group`:  same as `quantity` <br>\n",
    "`payment_type`:  same as `payment` <br>\n",
    "`funder`: 1898 unique values; source of funding less relevant to pump functionality which should be better captured by `installer` <br>\n",
    "\n",
    "We replaced NaN values with `missing` to keep the rows in our dataframe. We will onehotencode the data frame later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a hold out data set which we will test our final model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, holdout = train_test_split(df, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('data/X_train.csv')\n",
    "X_test.to_csv('data/X_test.csv')\n",
    "y_train.to_csv('data/y_train.csv')\n",
    "y_test.to_csv('data/y_test.csv')\n",
    "\n",
    "df.to_csv('data/holdout_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.select_dtypes('int64', 'float64').columns\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(12, 6))\n",
    "fig.set_tight_layout(True)\n",
    "for index, col in enumerate(cols): \n",
    "    ax = axes[index//3][index%3]\n",
    "    ax.scatter(df[col], df.status_group, alpha=0.2)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Pump Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df.amount_tsh, df.status_group)\n",
    "ax.set_xlabel('Total Static Head')\n",
    "ax.set_title('Total Static Head by Pump Status');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df.construction_year.loc[df.construction_year != 0], \n",
    "           df.status_group.loc[df.construction_year !=0])\n",
    "ax.set_xlabel('Construction Year')\n",
    "ax.set_title('Construction Year by Pump Status');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df.population, df.status_group)\n",
    "ax.set_xlabel('Population Around the Well')\n",
    "ax.set_title('Population by Pump Status');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score Train:', dummy_model.score(X_train, y_train))\n",
    "print('Accuracy Score Test:', dummy_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_dummy = cross_val_score(dummy_model, X_train, y_train, scoring='neg_log_loss')\n",
    "log_loss_dummy = -log_loss_dummy.mean()\n",
    "print('Log Loss:', log_loss_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status_group.value_counts().plot(kind='bar', color='red')\n",
    "plt.title('Class Distribution', fontsize = 20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = viz_df.drop(viz_df[viz_df['longitude']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df[viz_df['longitude']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color palette as dictionary\n",
    "\n",
    "palette = {\"functional\":\"xkcd:soft green\",\n",
    "\"non functional\":\"xkcd:light red\",\n",
    "\"functional needs repair\":\"xkcd:cerulean\"\n",
    "}\n",
    "\n",
    "# https://xkcd.com/color/rgb/ - color options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='status_group', palette=palette, sizes=(1, 8), data=viz_df, ax=ax)\n",
    "plt.xlabel(\"Longitude\", fontweight='bold', size=12)\n",
    "plt.ylabel(\"Latitude\", fontweight='bold', size=12)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), borderaxespad=0)\n",
    "plt.title('Tanzania Well Status by Coordinates',fontweight='bold', size=16) # change this title\n",
    "plt.tight_layout()\n",
    "# fig.savefig('./images/map.png')\n",
    "\n",
    "# palette=\"ch: r=-.2, d=.3_r\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# import category_encoders as ce\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying features and target\n",
    "features = df.drop('status_group', axis=1)\n",
    "target = df.status_group\n",
    "\n",
    "# dummy the features\n",
    "dummy_features = pd.get_dummies(features, drop_first=True)\n",
    "dummy_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "def machine_learn(model):\n",
    "    model_pipeline = Pipeline([('ss', StandardScaler()), ('model', model)])\n",
    "    fitted_model = model_pipeline.fit(X_train, y_train)\n",
    "    print(\"Accuracy Score:\", fitted_model.score(X_test, y_test))\n",
    "    preds = fitted_model.predict(X_test)\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(sns.heatmap(confusion_matrix(y_test, preds)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dummy_features, target, test_size=0.2, random_state=123)\n",
    "\n",
    "# SMOTE\n",
    "X_resampled, y_resampled = SMOTE(sampling_strategy='minority',random_state = 123).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build model\n",
    "# tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# machine_learn(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build model\n",
    "# forest = RandomForestClassifier(random_state=123, verbose=1)\n",
    "\n",
    "# machine_learn(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_forest = {\n",
    "#     'max_depth': [15, 20, 25] ,\n",
    "#     'n_estimators': [150, 200, 250, 300],\n",
    "#     'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search_forest = GridSearchCV(\n",
    "#     estimator=forest,\n",
    "#     param_grid=parameters_forest,\n",
    "#     n_jobs = -1,\n",
    "#     cv = 5,\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier(learning_rate=0.05, max_depth=35, random_state=123, objective = 'multi:softprob', num_class=3, verbosity=1)\n",
    "# machine_learn(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decade'] = df['construction_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decade'].replace(to_replace = (1960, 1961, 1962, 1963, 1964, 1965,1966,1967,1968,1969, 1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989, 1990,1991,1992,1993,1994,1995,1996,1997,1998,1999 ), value = '20th Century')\n",
    "\n",
    "df['decade'].replace(to_replace = (2000,2001,2002,2003,2004,2005,2006,2007,2008,2009, 2010,2011,2012,2013), value = '21st Century')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
