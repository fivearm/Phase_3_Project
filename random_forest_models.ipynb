{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the presplit data\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40095 entries, 0 to 40094\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     40095 non-null  int64  \n",
      " 1   amount_tsh             40095 non-null  float64\n",
      " 2   funder                 40095 non-null  object \n",
      " 3   gps_height             40095 non-null  int64  \n",
      " 4   installer              40095 non-null  object \n",
      " 5   longitude              40095 non-null  float64\n",
      " 6   latitude               40095 non-null  float64\n",
      " 7   num_private            40095 non-null  int64  \n",
      " 8   basin                  40095 non-null  object \n",
      " 9   region                 40095 non-null  object \n",
      " 10  region_code            40095 non-null  int64  \n",
      " 11  district_code          40095 non-null  int64  \n",
      " 12  population             40095 non-null  int64  \n",
      " 13  public_meeting         40095 non-null  object \n",
      " 14  scheme_management      40095 non-null  object \n",
      " 15  permit                 40095 non-null  object \n",
      " 16  construction_year      40095 non-null  int64  \n",
      " 17  extraction_type        40095 non-null  object \n",
      " 18  extraction_type_group  40095 non-null  object \n",
      " 19  extraction_type_class  40095 non-null  object \n",
      " 20  management             40095 non-null  object \n",
      " 21  management_group       40095 non-null  object \n",
      " 22  payment                40095 non-null  object \n",
      " 23  payment_type           40095 non-null  object \n",
      " 24  water_quality          40095 non-null  object \n",
      " 25  quality_group          40095 non-null  object \n",
      " 26  quantity               40095 non-null  object \n",
      " 27  source                 40095 non-null  object \n",
      " 28  source_type            40095 non-null  object \n",
      " 29  source_class           40095 non-null  object \n",
      " 30  waterpoint_type        40095 non-null  object \n",
      " 31  waterpoint_type_group  40095 non-null  object \n",
      "dtypes: float64(3), int64(7), object(22)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.drop('id', axis = 1, inplace=True)\n",
    "X_test.drop('id', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "# X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.drop('id', inplace=True, axis = 1)\n",
    "y_test.drop('id', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(40095, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(13365, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train_nums = X_train.select_dtypes(exclude=object)\n",
    "X_test_nums = X_test.select_dtypes(exclude=object)\n",
    "\n",
    "X_train_nums_scaled = ss.fit_transform(X_train_nums)\n",
    "X_test_nums_scaled = ss.transform(X_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train_nums_scaled, y_train)\n",
    "\n",
    "preds = rfc.predict(X_test_nums_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mode's accuracy on the training data is 0.9858\n",
      "The Model's accuracy on the test data is 0.7166\n"
     ]
    }
   ],
   "source": [
    "train_scores = rfc.score(X_train_nums_scaled, y_train)\n",
    "test_scores = rfc.score(X_test_nums_scaled, y_test)\n",
    "print('The Mode\\'s accuracy on the training data is', round(train_scores, 4))\n",
    "print('The Model\\'s accuracy on the test data is', round(test_scores, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 1.0042233873961206\n"
     ]
    }
   ],
   "source": [
    "log_loss_rfc = cross_val_score(rfc, X_train_nums_scaled, y_train, scoring='neg_log_loss', n_jobs = -1)\n",
    "log_loss_rfc = -log_loss_rfc.mean()\n",
    "print('Log Loss:', log_loss_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inital model that only contains numerical data is severly overfitting the data. The next model will need to tune some hyperparameters to reduce the gap between the training and testing data. Our log loss has been decreased from the dummy classifer, but there is still room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline_1 = Pipeline([('ss', StandardScaler()), ('rfc', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('rfc', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'rfc': RandomForestClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'rfc__bootstrap': True,\n",
       " 'rfc__ccp_alpha': 0.0,\n",
       " 'rfc__class_weight': None,\n",
       " 'rfc__criterion': 'gini',\n",
       " 'rfc__max_depth': None,\n",
       " 'rfc__max_features': 'auto',\n",
       " 'rfc__max_leaf_nodes': None,\n",
       " 'rfc__max_samples': None,\n",
       " 'rfc__min_impurity_decrease': 0.0,\n",
       " 'rfc__min_impurity_split': None,\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__min_samples_split': 2,\n",
       " 'rfc__min_weight_fraction_leaf': 0.0,\n",
       " 'rfc__n_estimators': 100,\n",
       " 'rfc__n_jobs': None,\n",
       " 'rfc__oob_score': False,\n",
       " 'rfc__random_state': None,\n",
       " 'rfc__verbose': 0,\n",
       " 'rfc__warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipline_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_1 = {\n",
    "    'rfc__max_depth': list(range(5,50,5)),\n",
    "    'rfc__min_samples_leaf': list(range(5,50,5)),\n",
    "    'rfc__n_estimators': list(range(25,500,25)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 14.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                             ('rfc',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'rfc__max_depth': [5, 10, 15, 20, 25,\n",
       "                                                           30, 35, 40, 45],\n",
       "                                        'rfc__min_samples_leaf': [5, 10, 15, 20,\n",
       "                                                                  25, 30, 35,\n",
       "                                                                  40, 45],\n",
       "                                        'rfc__n_estimators': [25, 50, 75, 100,\n",
       "                                                              125, 150, 175,\n",
       "                                                              200, 225, 250,\n",
       "                                                              275, 300, 325,\n",
       "                                                              350, 375, 400,\n",
       "                                                              425, 450, 475]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_1 = RandomizedSearchCV(pipline_1, params_1, n_jobs=-1, verbose=2, n_iter=50)\n",
    "\n",
    "rs_1.fit(X_train_nums, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8274847237810201, 0.7215114104002993)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_1.score(X_train_nums, y_train), rs_1.score(X_test_nums, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__n_estimators': 350, 'rfc__min_samples_leaf': 5, 'rfc__max_depth': 40}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = False\n",
    "while x == True:\n",
    "    assert print('Need to fix the imbalance between the training data and the testing data')\n",
    "    assert print('Fix below')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nums = X_train.select_dtypes(exclude = object)\n",
    "\n",
    "X_train_cat = X_train.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "                \n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='first', handle_unknown = 'ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "ohe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = ColumnTransformer(transformers=[\n",
    "    ('numerical', numerical_pipeline, X_train_nums.columns),\n",
    "    ('categorical', categorical_pipeline, X_train_cat.columns)\n",
    "], verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = Pipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('rfr', RandomForestClassifier(verbose=1, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(steps=[('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
       "       'region_code', 'district_code', 'population', 'construction_year',\n",
       "       'funder_A/co Germany',\n",
       "       ...\n",
       "       'waterpoint_type_communal standpipe multiple', 'waterpoint_type_dam',\n",
       "       'wate...\n",
       "       'waterpoint_type_other', 'waterpoint_type_group_communal standpipe',\n",
       "       'waterpoint_type_group_dam', 'waterpoint_type_group_hand pump',\n",
       "       'waterpoint_type_group_improved spring', 'waterpoint_type_group_other'],\n",
       "      dtype='object', length=3520)),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore'))]),\n",
       "                                                  Index([], dtype='object'))],\n",
       "                                   verbose=True)),\n",
       "                ('rfr', RandomForestClassifier(n_jobs=-1, verbose=1))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9973063973063973"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the input must be equal to or greater than that of the fitted transformer. Transformer n_features is 3520 and input n_features is 2046.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-cf336db13fe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m             raise ValueError('Number of features of the input must be equal '\n\u001b[0m\u001b[0;32m    582\u001b[0m                              \u001b[1;34m'to or greater than that of the fitted '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m                              \u001b[1;34m'transformer. Transformer n_features is {0} '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the input must be equal to or greater than that of the fitted transformer. Transformer n_features is 3520 and input n_features is 2046."
     ]
    }
   ],
   "source": [
    "model_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_pipe.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_1 = cross_val_score(model_pipe, X_train, y_train, scoring='neg_log_loss', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89672136, 0.84950494, 0.88854785, 0.83429731, 0.85628461])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-cv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1 = cross_val_score(model_pipe, X_test, y_test, scoring='neg_log_loss', n_jobs = -1)\n",
    "-cv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
