{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "%time\n",
    "import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the presplit data\n",
    "X_train = pd.read_csv('data/X_train.csv', index_col='id')\n",
    "X_test = pd.read_csv('data/X_test.csv', index_col='id')\n",
    "y_train = pd.read_csv('data/y_train.csv', index_col='id')\n",
    "y_test = pd.read_csv('data/y_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40095 entries, 45522 to 9914\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   amount_tsh             40095 non-null  float64\n",
      " 1   funder                 40095 non-null  object \n",
      " 2   gps_height             40095 non-null  int64  \n",
      " 3   installer              40095 non-null  object \n",
      " 4   longitude              40095 non-null  float64\n",
      " 5   latitude               40095 non-null  float64\n",
      " 6   num_private            40095 non-null  int64  \n",
      " 7   basin                  40095 non-null  object \n",
      " 8   region                 40095 non-null  object \n",
      " 9   region_code            40095 non-null  int64  \n",
      " 10  district_code          40095 non-null  int64  \n",
      " 11  population             40095 non-null  int64  \n",
      " 12  public_meeting         40095 non-null  object \n",
      " 13  scheme_management      40095 non-null  object \n",
      " 14  permit                 40095 non-null  object \n",
      " 15  construction_year      40095 non-null  int64  \n",
      " 16  extraction_type        40095 non-null  object \n",
      " 17  extraction_type_group  40095 non-null  object \n",
      " 18  extraction_type_class  40095 non-null  object \n",
      " 19  management             40095 non-null  object \n",
      " 20  management_group       40095 non-null  object \n",
      " 21  payment                40095 non-null  object \n",
      " 22  payment_type           40095 non-null  object \n",
      " 23  water_quality          40095 non-null  object \n",
      " 24  quality_group          40095 non-null  object \n",
      " 25  quantity               40095 non-null  object \n",
      " 26  source                 40095 non-null  object \n",
      " 27  source_type            40095 non-null  object \n",
      " 28  source_class           40095 non-null  object \n",
      " 29  waterpoint_type        40095 non-null  object \n",
      " 30  waterpoint_type_group  40095 non-null  object \n",
      "dtypes: float64(3), int64(6), object(22)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "# X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(40095, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(13365, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train_nums = X_train.select_dtypes(exclude=object)\n",
    "X_test_nums = X_test.select_dtypes(exclude=object)\n",
    "\n",
    "X_train_nums_scaled = ss.fit_transform(X_train_nums)\n",
    "X_test_nums_scaled = ss.transform(X_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "rfc.fit(X_train_nums_scaled, y_train)\n",
    "\n",
    "preds = rfc.predict(X_test_nums_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mode's accuracy on the training data is 0.9858\n",
      "The Model's accuracy on the test data is 0.7167\n"
     ]
    }
   ],
   "source": [
    "train_scores = rfc.score(X_train_nums_scaled, y_train)\n",
    "test_scores = rfc.score(X_test_nums_scaled, y_test)\n",
    "print('The Mode\\'s accuracy on the training data is', round(train_scores, 4))\n",
    "print('The Model\\'s accuracy on the test data is', round(test_scores, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 1.0189239606183915\n"
     ]
    }
   ],
   "source": [
    "log_loss_rfc = cross_val_score(rfc, X_train_nums_scaled, y_train, scoring='neg_log_loss', n_jobs = -2, cv = 2)\n",
    "log_loss_rfc = -log_loss_rfc.mean()\n",
    "print('Log Loss:', log_loss_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inital model that only contains numerical data is severly overfitting the data. The next model will need to tune some hyperparameters to reduce the gap between the training and testing data. Our log loss has been decreased from the dummy classifer, but there is still room for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning some hyperparameters to see if the model can be improved\n",
    "\n",
    "No categorial colums have yet been introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline_1 = Pipeline([('ss', StandardScaler()), ('rfc', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('rfc', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'rfc': RandomForestClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'rfc__bootstrap': True,\n",
       " 'rfc__ccp_alpha': 0.0,\n",
       " 'rfc__class_weight': None,\n",
       " 'rfc__criterion': 'gini',\n",
       " 'rfc__max_depth': None,\n",
       " 'rfc__max_features': 'auto',\n",
       " 'rfc__max_leaf_nodes': None,\n",
       " 'rfc__max_samples': None,\n",
       " 'rfc__min_impurity_decrease': 0.0,\n",
       " 'rfc__min_impurity_split': None,\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__min_samples_split': 2,\n",
       " 'rfc__min_weight_fraction_leaf': 0.0,\n",
       " 'rfc__n_estimators': 100,\n",
       " 'rfc__n_jobs': None,\n",
       " 'rfc__oob_score': False,\n",
       " 'rfc__random_state': None,\n",
       " 'rfc__verbose': 0,\n",
       " 'rfc__warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipline_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_1 = {\n",
    "    'rfc__max_depth': list(range(5,50,5)),\n",
    "    'rfc__min_samples_leaf': list(range(5,50,5)),\n",
    "    'rfc__n_estimators': list(range(25,500,25)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-2)]: Done  50 out of  50 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                             ('rfc',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-2,\n",
       "                   param_distributions={'rfc__max_depth': [5, 10, 15, 20, 25,\n",
       "                                                           30, 35, 40, 45],\n",
       "                                        'rfc__min_samples_leaf': [5, 10, 15, 20,\n",
       "                                                                  25, 30, 35,\n",
       "                                                                  40, 45],\n",
       "                                        'rfc__n_estimators': [25, 50, 75, 100,\n",
       "                                                              125, 150, 175,\n",
       "                                                              200, 225, 250,\n",
       "                                                              275, 300, 325,\n",
       "                                                              350, 375, 400,\n",
       "                                                              425, 450, 475]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_1 = RandomizedSearchCV(pipline_1, params_1, n_jobs=-2, verbose=3, n_iter=10)\n",
    "\n",
    "rs_1.fit(X_train_nums, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score for the random search with some hyperparameter tuning is 0.8274\n",
      "\n",
      "The test score for the random search with some hyperparameter tuning is 0.7212\n"
     ]
    }
   ],
   "source": [
    "print('The train score for the random search with some hyperparameter tuning is',\n",
    "      round(rs_1.score(X_train_nums, y_train), 4))\n",
    "print('')\n",
    "print('The test score for the random search with some hyperparameter tuning is',\n",
    "      round(rs_1.score(X_test_nums, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__n_estimators': 375, 'rfc__min_samples_leaf': 5, 'rfc__max_depth': 30}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.677179717281616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "log_loss_rfc = cross_val_score(rs_1, X_train_nums_scaled, y_train, scoring='neg_log_loss', n_jobs = -2, verbose=1, cv = 2)\n",
    "log_loss_rfc = -log_loss_rfc.mean()\n",
    "print('Log Loss:', log_loss_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is he first model that will contain the categorical colums, there will be no hyperparameter tuning done yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nums = X_train.select_dtypes(exclude = object)\n",
    "\n",
    "X_train_cat = X_train.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "                \n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "ohe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = ColumnTransformer(transformers=[\n",
    "    ('numerical', numerical_pipeline, X_train_nums.columns),\n",
    "    ('categorical', categorical_pipeline, X_train_cat.columns)\n",
    "], verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = imbPipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rfc', RandomForestClassifier(verbose=1, n_jobs=-2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(steps=[('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
       "       'region_code', 'district_code', 'population', 'construction_year'],\n",
       "      dtype='object')),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))...\n",
       "       'scheme_management', 'permit', 'extraction_type',\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'source', 'source_type', 'source_class',\n",
       "       'waterpoint_type', 'waterpoint_type_group'],\n",
       "      dtype='object'))],\n",
       "                                   verbose=True)),\n",
       "                ('smote', SMOTE(random_state=42)),\n",
       "                ('rfc', RandomForestClassifier(n_jobs=-2, verbose=1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9963586482105"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7873550317994762"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   49.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   49.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9206636703988862"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1 = cross_val_score(model_pipe, X_train, y_train, scoring='neg_log_loss', n_jobs = -2, verbose = 3, cv = 2)\n",
    "-cv_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   10.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8820308158165975"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1 = cross_val_score(model_pipe, X_test, y_test, scoring='neg_log_loss', n_jobs = -2, verbose = 3, cv = 2)\n",
    "-cv_1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first model is a significant improvement from the first Random Forst Classifer model. The train score increase by $0.0736$. However, the model is still significanly overfitting and that will need to be reduced by hyperparameter tuning. \n",
    "\n",
    "The log loss also improved from $1.005$ with the first model with only numeric colums to $0.8861$ with all colums included. This was an improvement of $0.1188$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training scores are severly overfitting the test scores in the data I will first limit the max depth of the tree. This should certainly help to limit overfitting. I will leave other hyperparamters in their default state for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_1 = Pipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('rfc', RandomForestClassifier(verbose=1, n_jobs=-2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('trans', ColumnTransformer(n_jobs=-1,\n",
       "                     transformers=[('numerical',\n",
       "                                    Pipeline(steps=[('ss', StandardScaler())]),\n",
       "                                    Index(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
       "          'region_code', 'district_code', 'population', 'construction_year'],\n",
       "         dtype='object')),\n",
       "                                   ('categorical',\n",
       "                                    Pipeline(steps=[('ohe',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    Index(['funder', 'installer', 'basin', 'region', 'public_meeting',\n",
       "          'scheme_management', 'permit', 'extraction_type',\n",
       "          'extraction_type_group', 'extraction_type_class', 'management',\n",
       "          'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "          'quality_group', 'quantity', 'source', 'source_type', 'source_class',\n",
       "          'waterpoint_type', 'waterpoint_type_group'],\n",
       "         dtype='object'))],\n",
       "                     verbose=True)),\n",
       "  ('rfc', RandomForestClassifier(n_jobs=-2, verbose=1))],\n",
       " 'verbose': False,\n",
       " 'trans': ColumnTransformer(n_jobs=-1,\n",
       "                   transformers=[('numerical',\n",
       "                                  Pipeline(steps=[('ss', StandardScaler())]),\n",
       "                                  Index(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
       "        'region_code', 'district_code', 'population', 'construction_year'],\n",
       "       dtype='object')),\n",
       "                                 ('categorical',\n",
       "                                  Pipeline(steps=[('ohe',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  Index(['funder', 'installer', 'basin', 'region', 'public_meeting',\n",
       "        'scheme_management', 'permit', 'extraction_type',\n",
       "        'extraction_type_group', 'extraction_type_class', 'management',\n",
       "        'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "        'quality_group', 'quantity', 'source', 'source_type', 'source_class',\n",
       "        'waterpoint_type', 'waterpoint_type_group'],\n",
       "       dtype='object'))],\n",
       "                   verbose=True),\n",
       " 'rfc': RandomForestClassifier(n_jobs=-2, verbose=1),\n",
       " 'trans__n_jobs': -1,\n",
       " 'trans__remainder': 'drop',\n",
       " 'trans__sparse_threshold': 0.3,\n",
       " 'trans__transformer_weights': None,\n",
       " 'trans__transformers': [('numerical',\n",
       "   Pipeline(steps=[('ss', StandardScaler())]),\n",
       "   Index(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
       "          'region_code', 'district_code', 'population', 'construction_year'],\n",
       "         dtype='object')),\n",
       "  ('categorical',\n",
       "   Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   Index(['funder', 'installer', 'basin', 'region', 'public_meeting',\n",
       "          'scheme_management', 'permit', 'extraction_type',\n",
       "          'extraction_type_group', 'extraction_type_class', 'management',\n",
       "          'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "          'quality_group', 'quantity', 'source', 'source_type', 'source_class',\n",
       "          'waterpoint_type', 'waterpoint_type_group'],\n",
       "         dtype='object'))],\n",
       " 'trans__verbose': True,\n",
       " 'trans__numerical': Pipeline(steps=[('ss', StandardScaler())]),\n",
       " 'trans__categorical': Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'trans__numerical__memory': None,\n",
       " 'trans__numerical__steps': [('ss', StandardScaler())],\n",
       " 'trans__numerical__verbose': False,\n",
       " 'trans__numerical__ss': StandardScaler(),\n",
       " 'trans__numerical__ss__copy': True,\n",
       " 'trans__numerical__ss__with_mean': True,\n",
       " 'trans__numerical__ss__with_std': True,\n",
       " 'trans__categorical__memory': None,\n",
       " 'trans__categorical__steps': [('ohe',\n",
       "   OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'trans__categorical__verbose': False,\n",
       " 'trans__categorical__ohe': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'trans__categorical__ohe__categories': 'auto',\n",
       " 'trans__categorical__ohe__drop': None,\n",
       " 'trans__categorical__ohe__dtype': numpy.float64,\n",
       " 'trans__categorical__ohe__handle_unknown': 'ignore',\n",
       " 'trans__categorical__ohe__sparse': True,\n",
       " 'rfc__bootstrap': True,\n",
       " 'rfc__ccp_alpha': 0.0,\n",
       " 'rfc__class_weight': None,\n",
       " 'rfc__criterion': 'gini',\n",
       " 'rfc__max_depth': None,\n",
       " 'rfc__max_features': 'auto',\n",
       " 'rfc__max_leaf_nodes': None,\n",
       " 'rfc__max_samples': None,\n",
       " 'rfc__min_impurity_decrease': 0.0,\n",
       " 'rfc__min_impurity_split': None,\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__min_samples_split': 2,\n",
       " 'rfc__min_weight_fraction_leaf': 0.0,\n",
       " 'rfc__n_estimators': 100,\n",
       " 'rfc__n_jobs': -2,\n",
       " 'rfc__oob_score': False,\n",
       " 'rfc__random_state': None,\n",
       " 'rfc__verbose': 1,\n",
       " 'rfc__warm_start': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'rfc__max_depth': list(range(10,100,10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  12 out of  18 | elapsed:  2.0min remaining:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done  18 out of  18 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('trans',\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          transformers=[('numerical',\n",
       "                                                                         Pipeline(steps=[('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
       "       'region_code', 'district_code', 'population', 'construction_year'],\n",
       "      dtype='object')),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncod...\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'source', 'source_type', 'source_class',\n",
       "       'waterpoint_type', 'waterpoint_type_group'],\n",
       "      dtype='object'))],\n",
       "                                                          verbose=True)),\n",
       "                                       ('rfc',\n",
       "                                        RandomForestClassifier(n_jobs=-2,\n",
       "                                                               verbose=1))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'rfc__max_depth': [10, 20, 30, 40, 50, 60, 70, 80,\n",
       "                                            90]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_1 = GridSearchCV(model_pipe_1, params, n_jobs=-2, verbose=3, cv = 2)\n",
    "gs_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.937797730390323"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8055368499812944"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   25.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8668872820124996"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1 = cross_val_score(model_pipe_1, X_train, y_train, scoring='neg_log_loss', n_jobs = -2, verbose = 3, cv = 2)\n",
    "-cv_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9492371018382766"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1 = cross_val_score(model_pipe_1, X_test, y_test, scoring='neg_log_loss', n_jobs = -2, verbose = 1, cv = 2)\n",
    "-cv_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 30}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second iteration I will still change max depth, but will also change the number of estimators to see how a change in the number of trees would effect the accuracy score. I will also use criterion to see if it has any effect on the score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_2 = Pipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('rfc', RandomForestClassifier(verbose=1, n_jobs=-2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'rfc__max_depth': list(range(10,100,10)),\n",
    "    'rfc__criterion': ['gini', 'entropy'],\n",
    "    'rfc__n_estimators': list(range(50,250,50))   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-b3e23ee060cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgs_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_pipe_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gs_2 = GridSearchCV(model_pipe_2, params, n_jobs=-2, verbose=3, cv = 2)\n",
    "gs_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_1 = cross_val_score(model_pipe_2, X_train, y_train, scoring='neg_log_loss', n_jobs = -2, verbose = 1, cv = 2)\n",
    "-cv_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_1 = cross_val_score(model_pipe_2, X_test, y_test, scoring='neg_log_loss', n_jobs = -2, verbose = 1, cv = 2)\n",
    "-cv_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
